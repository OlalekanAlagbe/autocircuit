===================================================================================
FEATURE HYPOTHESES SUMMARY FOR "DNA STANDS FOR DEOXYRIBONUCLEIC"
===================================================================================

## KEY FEATURES TO VALIDATE (From Circuit Analysis)

### HYPOTHESIS 1: Scientific Domain Features
**Location:** L0-L2, Context position 1 (DNA token)
**Expected:** Features detecting scientific/biology domain context

Top 5 Features from L0_C1:
- Feature 122500377: Influence 0.796, Activation 1.36
- Feature 63545: Influence 0.796, Activation 1.73
- Feature 130969019: Influence 0.788, Activation 1.67
- Feature 5131205: Influence 0.780, Activation 1.60
- Feature 744809: Influence 0.779, Activation 1.03

### HYPOTHESIS 2: Definitional Structure Features  
**Location:** L1-L2, Context positions 2-3 ("stands for")
**Expected:** Features detecting definitional/explanatory patterns

Top 3 Features from L1_C2 (stands):
- Feature 38084626: Influence 0.789
- Feature 99962728: Influence 0.786
- Feature 88398454: Influence 0.784

Top 3 Features from L2_C3 (for):
- Feature 59759775: Influence 0.797
- Feature 1745643: Influence 0.783
- Feature 65133988: Influence 0.773

### HYPOTHESIS 3: "Deoxy-" Prefix Features
**Location:** L6-L10, Context position 4 ("deoxy" token)
**Expected:** Features recognizing chemical prefix, predicting continuation

Top 5 Features from L7-L10_C4:
- Feature 114587083 (L7): Influence 0.793, Activation 6.27
- Feature 93413938 (L7): Influence 0.776, Activation 7.42
- Feature 2946370 (L7): Influence 0.742, Activation 12.13
- Feature 5096018 (L9): Influence 0.742, Activation 14.65
- Feature 2910070 (L7): Influence 0.725, Activation 11.37

### HYPOTHESIS 4: Integration Hub Features
**Location:** L23, Context position 6 (target)
**Expected:** High in-degree nodes combining multiple evidence sources

Top 5 Hub Features from L23_C6:
- Feature 22194429: In-degree 610, Influence 0.271, Activation 42.36
- Feature 16753342: In-degree 475, Influence 0.303, Activation 32.59
- Feature 17650687: In-degree 380, Influence 0.319, Activation 76.06
- Feature 96625827: In-degree 246, Influence 0.331, Activation 109.00
- Feature 12164754: In-degree 234, Influence 0.363, Activation 19.12

### HYPOTHESIS 5: Token-Specific Boosting Features
**Location:** L25, Context position 6 (target → output)
**Expected:** Features specifically boosting "bonucleic" token logit

Top Feature with Strongest Output Connection:
- Feature 11250370: Edge weight 0.865 to output, Influence 0.278, Activation 272.29

===================================================================================
PREDICTED FEATURE SEMANTICS
===================================================================================

HYPOTHESIS 1 (Domain Features):
✓ Should activate on: DNA, RNA, ATP, enzyme names, scientific acronyms
✓ Role: Prime scientific vocabulary domain for output

HYPOTHESIS 2 (Definitional Features):
✓ Should activate on: "stands for", "means", "refers to", "is called"
✓ Role: Detect definition structure, route expansion to target position

HYPOTHESIS 3 (Prefix Features):
✓ Should activate on: "deoxy", "deoxyribose", "deoxygenated", chemical prefixes
✓ Role: Recognize incomplete morpheme, predict "-ribonucleic" continuation

HYPOTHESIS 4 (Integration Hubs):
✓ Should activate on: Complex multi-constraint prediction tasks
✓ Role: Combine DNA + definition + deoxy context → final decision
✓ Note: Lower influence but VERY high in-degree (610, 475, 380 edges)

HYPOTHESIS 5 (Token Boosting):
✓ Should activate on: "bonucleic", "ribonucleic acid" contexts
✓ Role: Final boost to specific token logit
✓ Note: Extremely high activation (272.29) suggests sharp feature

===================================================================================
VALIDATION APPROACH
===================================================================================

For each feature, look up on Neuronpedia:
https://neuronpedia.org/gemma-2-2b/gemmascope-transcoder-16k/{FEATURE_ID}

Check:
1. Top activating examples - do they match hypothesis?
2. Activation distribution - is it narrow (specific) or broad (general)?
3. Associated text patterns - semantically related to prediction?

Validation metrics:
- Hypothesis confirmation rate = confirmed / total sampled
- Surprising findings count = unexpected feature semantics
- Polysemanticity check = features serving multiple roles

===================================================================================
EXPECTED VS. COUNTER-EXPECTED FINDINGS
===================================================================================

SHOULD FIND:
✓ Scientific terms in early layers
✓ Grammatical structures in early layers
✓ Prefix/morphology processing in middle layers
✓ High-degree integration hubs in late layers
✓ Token-specific features in final layer

SHOULD NOT FIND:
✗ Generic word frequency features in late layers
✗ Grammatical features (verb/noun) in L22-L25
✗ Unrelated domain features (sports, politics, food)
✗ Random or noise patterns

===================================================================================
