"""Grouping module for creating supernodes from pinned nodes"""

from dataclasses import dataclass
from typing import List, Tuple
from .graph_analyzer import GraphAnalyzer


@dataclass
class Supernode:
    """Represents a group of nodes with similar function"""
    label: str  # Will be generated by AutoLabeler
    node_ids: List[str]
    layer_range: Tuple[int, int]
    functional_role: str  # "input_detector", "relational_processor", "output_promoter"
    total_influence: float


class GroupingEngine:
    """Group pinned nodes into supernodes representing functional modules"""

    def __init__(self, analyzer: GraphAnalyzer, pinned_nodes: List[str]):
        self.analyzer = analyzer
        self.pinned_nodes = pinned_nodes

    def create_supernodes(self, strategy: str = "functional") -> List[Supernode]:
        """
        Group nodes into supernodes using:

        - "functional": Group by computational role (input detectors, processors, output promoters)
        - "semantic": Group by semantic similarity (features detecting same concept)
        - "layer": Group by layer proximity
        - "hybrid": Combination of functional and semantic

        Returns: List of Supernode objects
        """
        if strategy == "functional":
            return self._functional_grouping()
        elif strategy == "semantic":
            return self._semantic_grouping()
        elif strategy == "layer":
            return self._layer_grouping()
        elif strategy == "hybrid":
            return self._hybrid_grouping()
        else:
            raise ValueError(f"Unknown strategy: {strategy}")

    def _functional_grouping(self) -> List[Supernode]:
        """
        Classify each node by role:
        - Input detectors: Activate on specific input tokens, early layers
        - Relational processors: Encode relationships between concepts, middle layers
        - Output promoters: Boost specific output tokens, late layers

        Group nodes with the same role and strong interconnections
        """
        supernodes = []

        # Classify nodes by role
        roles = {
            'input_detector': [],
            'relational_processor': [],
            'output_promoter': []
        }

        for node_id in self.pinned_nodes:
            node = self.analyzer.get_node(node_id)
            if not node:
                continue

            layer = node.get('layer', 0)

            # Check if it's an output promoter (late layer + high logit influence)
            if layer >= 16:
                logit_influence = sum(
                    e['weight'] for e in self.analyzer.edges
                    if e['source'] == node_id and e['target'].startswith('logit_')
                )
                if logit_influence > 0.1:
                    roles['output_promoter'].append(node_id)
                    continue

            # Check if it's an input detector (early layer)
            if layer <= 5:
                roles['input_detector'].append(node_id)
                continue

            # Otherwise it's a middle processor
            roles['relational_processor'].append(node_id)

        # Create supernodes for each role
        for role, node_list in roles.items():
            if not node_list:
                continue

            # Get layer range
            layers = [self.analyzer.get_node(nid).get('layer', 0) for nid in node_list]
            min_layer = min(layers)
            max_layer = max(layers)

            # Calculate total influence
            total_influence = sum(
                sum(e['weight'] for e in self.analyzer.edges if e['source'] == nid)
                for nid in node_list
            )

            if len(node_list) <= 3:
                # Small enough to be one supernode
                supernodes.append(Supernode(
                    label="",  # To be filled by AutoLabeler
                    node_ids=node_list,
                    layer_range=(min_layer, max_layer),
                    functional_role=role,
                    total_influence=total_influence
                ))
            else:
                # Further subdivide by layer proximity
                # Group nodes within 3 layers of each other
                sorted_nodes = sorted(node_list, key=lambda nid: self.analyzer.get_node(nid).get('layer', 0))

                current_group = [sorted_nodes[0]]
                current_layer = self.analyzer.get_node(sorted_nodes[0]).get('layer', 0)

                for nid in sorted_nodes[1:]:
                    node_layer = self.analyzer.get_node(nid).get('layer', 0)

                    if node_layer - current_layer <= 3:
                        current_group.append(nid)
                    else:
                        # Save current group and start new one
                        group_layers = [self.analyzer.get_node(n).get('layer', 0) for n in current_group]
                        group_influence = sum(
                            sum(e['weight'] for e in self.analyzer.edges if e['source'] == n)
                            for n in current_group
                        )
                        supernodes.append(Supernode(
                            label="",
                            node_ids=current_group,
                            layer_range=(min(group_layers), max(group_layers)),
                            functional_role=role,
                            total_influence=group_influence
                        ))
                        current_group = [nid]
                        current_layer = node_layer

                # Add final group
                if current_group:
                    group_layers = [self.analyzer.get_node(n).get('layer', 0) for n in current_group]
                    group_influence = sum(
                        sum(e['weight'] for e in self.analyzer.edges if e['source'] == n)
                        for n in current_group
                    )
                    supernodes.append(Supernode(
                        label="",
                        node_ids=current_group,
                        layer_range=(min(group_layers), max(group_layers)),
                        functional_role=role,
                        total_influence=group_influence
                    ))

        return supernodes

    def _semantic_grouping(self) -> List[Supernode]:
        """
        Use feature explanations and max-activating examples to group:
        1. Embed each feature's explanation using sentence-transformers
        2. Cluster embeddings using HDBSCAN or hierarchical clustering
        3. Validate clusters by checking if features have similar activation patterns
        """
        # TODO: Implement semantic grouping using embeddings
        # For now, fall back to functional grouping
        return self._functional_grouping()

    def _layer_grouping(self) -> List[Supernode]:
        """Group nodes by layer proximity"""
        # TODO: Implement layer-based grouping
        return self._functional_grouping()

    def _hybrid_grouping(self) -> List[Supernode]:
        """Combination of functional and semantic grouping"""
        # TODO: Implement hybrid grouping
        return self._functional_grouping()
